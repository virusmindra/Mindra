import os
import openai
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

openai.api_key = OPENAI_API_KEY

# /start –∫–æ–º–∞–Ω–¥–∞
async def start(update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç, —è Mindra ‚Äî —Ç–≤–æ–π AI-–∫–æ–º–ø–∞–Ω—å–æ–Ω üíú –ü–æ–¥–¥–µ—Ä–∂–∫–∞, –º–æ—Ç–∏–≤–∞—Ü–∏—è –∏ –Ω–µ–º–Ω–æ–≥–æ –ø—Å–∏—Ö–æ–ª–æ–≥. –ì–æ—Ç–æ–≤ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å!")

# –ß–∞—Ç —Å GPT
async def chat(update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text

    messages = [
        {"role": "system", "content": "–¢—ã ‚Äî —Ñ–ª–∏—Ä—Ç—É—é—â–∏–π, –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–π –∏ –∑–∞–±–æ—Ç–ª–∏–≤—ã–π AI-–∫–æ–º–ø–∞–Ω—å–æ–Ω –ø–æ –∏–º–µ–Ω–∏ Mindra."},
        {"role": "user", "content": user_input}
    ]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages
        )
        reply = response.choices[0].message.content
        await update.message.reply_text(reply)
    except Exception as e:
        await update.message.reply_text("–£–ø—Å, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–≤–∏—Å... –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ üò¢")
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI: {e}")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == "__main__":
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))
    print("ü§ñ Mindra –∑–∞–ø—É—â–µ–Ω!")
    app.run_polling()
